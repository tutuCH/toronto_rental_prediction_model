{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompose\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_column_transformer\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"toronto_rental_prediction_v2.h5\")\n",
    "rental = pd.read_csv(\"./Toronto_apartment_rentals_2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X & y\n",
    "X = rental.drop([\"Price\", \"Address\"], axis=1)\n",
    "y = rental[\"Price\"]\n",
    "data = [2, 1, 0, 43.648861, -79.378033]\n",
    "columns = [\"Bedroom\", \"Bathroom\", \"Den\", \"Lat\", \"Long\"]\n",
    "df = pd.DataFrame([data], columns=columns)\n",
    "# Create column transformer (this will help us normalize/preprocess our data)\n",
    "ct = make_column_transformer(\n",
    "    (MinMaxScaler(), columns), # get all values between 0 and 1\n",
    ")\n",
    "\n",
    "# Build our train and test sets (use random state to ensure same split as before)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Fit column transformer on the training data only (doing so on test data would result in data leakage)\n",
    "ct.fit(X_train)\n",
    "\n",
    "# Transform training and test data with normalization (MinMaxScalar) and one hot encoding (OneHotEncoder)\n",
    "X_test_normal = ct.transform(df)\n",
    "result = model.predict(X_test_normal)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your TensorFlow model takes normalized data as input (for example, data that has been scaled using a `MinMaxScaler`), you'll need to normalize your input data before making predictions with the model.\n",
    "\n",
    "Here are the general steps to do this:\n",
    "\n",
    "1. Load the model: Load the TensorFlow model using the `tf.loadLayersModel()` method or another suitable method, as described in my previous answer.\n",
    "\n",
    "2. Normalize the input data: Normalize your input data using the same scaling method or function that was used to normalize the training data. You can use the `fit_transform()` method of the scaler object to normalize your input data.\n",
    "\n",
    "Here's an example of how to normalize input data using a `MinMaxScaler` object:\n",
    "\n",
    "```typescript\n",
    "import * as tf from '@tensorflow/tfjs';\n",
    "import { MinMaxScaler } from 'sklearn-preprocessing';\n",
    "\n",
    "async function loadModel(path: string): Promise<tf.LayersModel> {\n",
    "  const model = await tf.loadLayersModel(path);\n",
    "  return model;\n",
    "}\n",
    "\n",
    "const model = await loadModel('path/to/your/model.json');\n",
    "\n",
    "const scaler = new MinMaxScaler();\n",
    "const inputData = [[2, 1, 1, 43.648861, -79.378033]];\n",
    "const normalizedInputData = scaler.fit_transform(inputData);\n",
    "```\n",
    "\n",
    "In this example, we load the TensorFlow model using the `tf.loadLayersModel()` method and create a new `MinMaxScaler` object. We then create an input data array `inputData` containing unnormalized input data and use the `fit_transform()` method of the scaler object to normalize the input data and assign the resulting normalized data to the `normalizedInputData` variable.\n",
    "\n",
    "3. Make predictions: Use the `model.predict()` method to make predictions with your normalized input data. Here's an example:\n",
    "\n",
    "```typescript\n",
    "const outputData = model.predict(normalizedInputData);\n",
    "console.log(outputData);\n",
    "```\n",
    "\n",
    "In this example, we use the `model.predict()` method to make predictions with the normalized input data and assign the resulting output Tensor object to the `outputData` variable. We then log the `outputData` variable to the console.\n",
    "\n",
    "Note that the input data must match the input shape of your model, and the output data will be a Tensor or an array of Tensors that match the output shape of your model.\n",
    "\n",
    "By normalizing your input data before making predictions with your TensorFlow model, you can ensure that your predictions are accurate and consistent with the model's training data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
